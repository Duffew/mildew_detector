{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39095f92",
   "metadata": {},
   "source": [
    "# **Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabdd41a",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Download data from Kaggle and prepare it for processing\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- kaggle.json - authntication token\n",
    "- dataset - images\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- Generated dataset: inputs/datasets/mildew_dataset\n",
    "- Split dataset - train, test, validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9b545d",
   "metadata": {},
   "source": [
    "## Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee078de5",
   "metadata": {},
   "source": [
    "By default, the working directory is \"jupyter_notebooks\", where the notebook is running. However, we need to change the working directory to its parent folder so that file references align with the broader project structure.\n",
    "\n",
    "To do this, we first check the current working directory — note that the output below only displays the last two folders in the file path, rather than the full system path. This is done intentionally to prevent exposing the full local file path stored on my machine.\n",
    "\n",
    "**Any time you revisit this notebook after logging out, or open a different notebook for the first time, you must repeat these steps to ensure the working directory is always correctly set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "750a5553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 mildew_detector\\jupyter_notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path # ensure file path consistency\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# Extract the last two directory names\n",
    "filtered_path = Path(*current_dir.parts[-2:])\n",
    "print(f\"📂 {filtered_path}\")  # Example output: 📂 mildew_detector/jupyter_notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31994a0",
   "metadata": {},
   "source": [
    "Now we change the working directory from \"jupyter_notebooks\" to the parent directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349a9320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "# Change the working directory to its parent folder\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Confirmation message with\n",
    "print(\"✅ You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c796bd",
   "metadata": {},
   "source": [
    "Confirm the new current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5891f58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Projects\\mildew_detector\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# Extract the last two directory names\n",
    "filtered_path = Path(*current_dir.parts[-2:])\n",
    "print(f\"📂 {filtered_path}\")  # Example output: 📂 mildew_detector/jupyter_notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d6abe4",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "029e03cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt-'\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt- fix this at the end with a new requirememts file curated from actual use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6089e89",
   "metadata": {},
   "source": [
    "## Install Kaggle\n",
    "\n",
    "Now we need to think about gathering our data. We will be downloading our images from kaggle.com so we first install kaggle to help with the download.\n",
    "\n",
    "For this you need to have your Kaggle Token handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e48c01e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle==1.5.12 in c:\\users\\nickd\\onedrive\\desktop\\projects\\mildew_detector\\.venv\\lib\\site-packages (1.5.12)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\nickd\\onedrive\\desktop\\projects\\mildew_detector\\.venv\\lib\\site-packages (from kaggle==1.5.12) (1.17.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\nickd\\onedrive\\desktop\\projects\\mildew_detector\\.venv\\lib\\site-packages (from kaggle==1.5.12) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\nickd\\onedrive\\desktop\\projects\\mildew_detector\\.venv\\lib\\site-packages (from kaggle==1.5.12) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in c:\\users\\nickd\\onedrive\\desktop\\projects\\mildew_detector\\.venv\\lib\\site-packages (from kaggle==1.5.12) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nickd\\onedrive\\desktop\\projects\\mildew_detector\\.venv\\lib\\site-packages (from kaggle==1.5.12) (4.67.1)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\nickd\\onedrive\\desktop\\projects\\mildew_detector\\.venv\\lib\\site-packages (from kaggle==1.5.12) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\nickd\\onedrive\\desktop\\projects\\mildew_detector\\.venv\\lib\\site-packages (from kaggle==1.5.12) (2.4.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\nickd\\onedrive\\desktop\\projects\\mildew_detector\\.venv\\lib\\site-packages (from python-slugify->kaggle==1.5.12) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nickd\\onedrive\\desktop\\projects\\mildew_detector\\.venv\\lib\\site-packages (from requests->kaggle==1.5.12) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nickd\\onedrive\\desktop\\projects\\mildew_detector\\.venv\\lib\\site-packages (from requests->kaggle==1.5.12) (3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\nickd\\onedrive\\desktop\\projects\\mildew_detector\\.venv\\lib\\site-packages (from tqdm->kaggle==1.5.12) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install kaggle package\n",
    "%pip install kaggle==1.5.12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1299105c",
   "metadata": {},
   "source": [
    "Drag and drop your kaggle.json file (Kaggle Token) into the same directory as README.md.\n",
    "\n",
    "The code below will check that kaggle.json appears in the directory by listing its contents. You should see a list of entries in this directory, including kaggle.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11fd9627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.gitignore', '.python-version', '.venv', 'jupyter_notebooks', 'README.md', 'requirements.txt', 'test.py']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir())  # Should list `kaggle.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b74b17e",
   "metadata": {},
   "source": [
    "Now we get the path for the dataset and set the destination folder where the downloaded images will be stored.\n",
    "\n",
    "This code will download a zip folder, then create new folders (\"inputs\" and \"cherry-leaves\") for storing the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc536291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading cherry-leaves.zip to inputs\\cherry-leaves\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/55.0M [00:00<?, ?B/s]\n",
      "  2%|▏         | 1.00M/55.0M [00:00<00:28, 1.97MB/s]\n",
      "  5%|▌         | 3.00M/55.0M [00:00<00:10, 5.28MB/s]\n",
      "  9%|▉         | 5.00M/55.0M [00:00<00:06, 8.00MB/s]\n",
      " 13%|█▎        | 7.00M/55.0M [00:00<00:04, 10.2MB/s]\n",
      " 16%|█▋        | 9.00M/55.0M [00:01<00:04, 11.7MB/s]\n",
      " 20%|█▉        | 11.0M/55.0M [00:01<00:03, 12.0MB/s]\n",
      " 24%|██▎       | 13.0M/55.0M [00:01<00:03, 11.9MB/s]\n",
      " 27%|██▋       | 15.0M/55.0M [00:01<00:03, 12.2MB/s]\n",
      " 31%|███       | 17.0M/55.0M [00:01<00:03, 12.1MB/s]\n",
      " 35%|███▍      | 19.0M/55.0M [00:01<00:03, 12.1MB/s]\n",
      " 38%|███▊      | 21.0M/55.0M [00:02<00:02, 12.3MB/s]\n",
      " 42%|████▏     | 23.0M/55.0M [00:02<00:02, 12.3MB/s]\n",
      " 45%|████▌     | 25.0M/55.0M [00:02<00:02, 12.5MB/s]\n",
      " 49%|████▉     | 27.0M/55.0M [00:02<00:02, 12.5MB/s]\n",
      " 53%|█████▎    | 29.0M/55.0M [00:02<00:02, 12.5MB/s]\n",
      " 56%|█████▋    | 31.0M/55.0M [00:02<00:02, 12.0MB/s]\n",
      " 60%|█████▉    | 33.0M/55.0M [00:03<00:01, 13.0MB/s]\n",
      " 64%|██████▎   | 35.0M/55.0M [00:03<00:01, 14.1MB/s]\n",
      " 67%|██████▋   | 37.0M/55.0M [00:03<00:01, 14.6MB/s]\n",
      " 71%|███████   | 39.0M/55.0M [00:03<00:01, 15.5MB/s]\n",
      " 75%|███████▍  | 41.0M/55.0M [00:03<00:00, 15.6MB/s]\n",
      " 78%|███████▊  | 43.0M/55.0M [00:03<00:00, 16.1MB/s]\n",
      " 82%|████████▏ | 45.0M/55.0M [00:03<00:00, 15.4MB/s]\n",
      " 85%|████████▌ | 47.0M/55.0M [00:03<00:00, 15.9MB/s]\n",
      " 89%|████████▉ | 49.0M/55.0M [00:04<00:00, 16.5MB/s]\n",
      " 93%|█████████▎| 51.0M/55.0M [00:04<00:00, 16.9MB/s]\n",
      " 96%|█████████▋| 53.0M/55.0M [00:04<00:00, 16.6MB/s]\n",
      "100%|█████████▉| 55.0M/55.0M [00:04<00:00, 17.0MB/s]\n",
      "100%|██████████| 55.0M/55.0M [00:04<00:00, 12.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Define Kaggle dataset and destination folder using pathlib\n",
    "KaggleDatasetPath = \"codeinstitute/cherry-leaves\"\n",
    "DestinationFolder = Path(\"inputs\") / \"cherry-leaves\"  # Ensures correct path handling across OS\n",
    "\n",
    "# Download the Kaggle dataset into the specified folder\n",
    "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebdb5aa",
   "metadata": {},
   "source": [
    "Now we need to unzip the downloaded file and get hold of the images. \n",
    "\n",
    "The cell below will unzip the file and store the images inside a new directory within the \"inputs\" folder.\n",
    "\n",
    "The code will also delete the zip file and your Kaggle Token for data protection purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "589138a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Extracted files into: inputs\\cherry-leaves\n",
      "🗑️ Deleted: inputs\\cherry-leaves\\cherry-leaves.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "zip_file = Path(\"inputs\") / \"cherry-leaves\" / \"cherry-leaves.zip\"\n",
    "extract_folder = Path(\"inputs\") / \"cherry-leaves\"\n",
    "kaggle_token = Path(\"kaggle.json\")\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "\n",
    "print(f\"📂 Extracted files into: {extract_folder}\")\n",
    "\n",
    "# Delete the zip file after extraction\n",
    "zip_file.unlink()\n",
    "print(f\"🗑️ Deleted: {zip_file}\")\n",
    "\n",
    "# Remove Kaggle token for security\n",
    "if kaggle_token.exists():\n",
    "    kaggle_token.unlink()\n",
    "    print(f\"🛡️ Kaggle Token removed: {kaggle_token}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe6268",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Now we have the images downloaded and stored in the right place, we need to ckeck that the data is suitable for our project.\n",
    "\n",
    "As we are concerned with using image data, we need to check that any non-image files are identified and removed.\n",
    "\n",
    "The function below will do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1c4ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def remove_non_image_files(my_data_dir):\n",
    "    \"\"\"\n",
    "    Removes all non-image files from the specified directory and its subfolders.\n",
    "\n",
    "    Args:\n",
    "        my_data_dir (str): Path to the directory containing image folders.\n",
    "\n",
    "    The function scans each folder within `my_data_dir`, identifies non-image files, \n",
    "    deletes them, and prints a summary of the number of image and non-image files per folder.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define valid image file extensions\n",
    "    image_extensions = {'.png', '.jpg', '.jpeg'}\n",
    "\n",
    "    # Convert the directory path to a Path object for better handling\n",
    "    my_data_dir = Path(my_data_dir)\n",
    "\n",
    "    # Check if directory exists\n",
    "    if not my_data_dir.exists():\n",
    "        print(f\"❌ Directory does not exist: {my_data_dir}\")\n",
    "        return\n",
    "\n",
    "    # Iterate through each folder in the main directory\n",
    "    for folder in my_data_dir.iterdir():\n",
    "        if folder.is_dir():  # Ensure we only process directories\n",
    "            image_count = 0\n",
    "            non_image_count = 0\n",
    "\n",
    "            # Iterate through files inside the folder\n",
    "            for given_file in folder.iterdir():\n",
    "                # Convert suffix safely and check extension\n",
    "                if given_file.suffix and given_file.suffix.lower() not in image_extensions:\n",
    "                    given_file.unlink()  # Remove non-image file\n",
    "                    non_image_count += 1\n",
    "                else:\n",
    "                    image_count += 1\n",
    "\n",
    "            # Print a summary of processed files\n",
    "            print(f\"📂 Folder: {folder.name} - has 📄 {image_count} image files\")\n",
    "            print(f\"📂 Folder: {folder.name} - has 📄 {non_image_count} non-image files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb21748",
   "metadata": {},
   "source": [
    "Now we call the function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62769aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Folder: healthy - has 📄 2104 image files\n",
      "📂 Folder: healthy - has 📄 0 non-image files\n",
      "📂 Folder: powdery_mildew - has 📄 2104 image files\n",
      "📂 Folder: powdery_mildew - has 📄 0 non-image files\n"
     ]
    }
   ],
   "source": [
    "remove_non_image_files(my_data_dir=r'inputs/cherry-leaves/cherry-leaves')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da492483",
   "metadata": {},
   "source": [
    "## Split the Data\n",
    "\n",
    "Now that we know the data is all images, we can split it into the groups we will need to build and fit a training model. These groups are:\n",
    "\n",
    "- Train set\n",
    "- Test set\n",
    "- Validation set\n",
    "\n",
    "The function below will create subfolders and split the data amongst them according to the arguments we define when calling the function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0611dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def split_train_validation_test_images(data_dir, train_ratio, val_ratio, test_ratio):\n",
    "    \"\"\"\n",
    "    Splits images into train, validation, and test sets based on given ratios.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str or Path): The directory containing subfolders of images, where each subfolder represents a class label.\n",
    "        train_ratio (float): The proportion of images allocated to the training set.\n",
    "        val_ratio (float): The proportion of images allocated to the validation set.\n",
    "        test_ratio (float): The proportion of images allocated to the test set.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the sum of train_ratio, val_ratio, and test_ratio is not equal to 1.0.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the ratios sum to 1.0 (rounded for floating-point precision)\n",
    "    if round(train_ratio + val_ratio + test_ratio, 5) != 1.0:\n",
    "        raise ValueError(\"train_ratio + val_ratio + test_ratio must sum to 1.0\")\n",
    "\n",
    "    # Convert data_dir to a Path object if not already\n",
    "    data_dir = Path(data_dir)\n",
    "\n",
    "    # Get only directories (class labels) inside the dataset directory\n",
    "    labels = [label for label in data_dir.iterdir() if label.is_dir()]\n",
    "\n",
    "    # Create train, validation, and test directories\n",
    "    for folder in ['train', 'validation', 'test']:\n",
    "        for label in labels:\n",
    "            (data_dir / folder / label.name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for label in labels:\n",
    "        files = [f for f in label.iterdir() if f.is_file()]  # List only files, ignoring subdirectories\n",
    "        random.shuffle(files)  # Shuffle to ensure randomness in splits\n",
    "\n",
    "        # Calculate split indices\n",
    "        train_count = int(len(files) * train_ratio)\n",
    "        val_count = int(len(files) * val_ratio)\n",
    "\n",
    "        # Iterate and move files to corresponding directories\n",
    "        for i, file_path in enumerate(files):\n",
    "            if i < train_count:\n",
    "                dst = data_dir / 'train' / label.name / file_path.name\n",
    "            elif i < train_count + val_count:\n",
    "                dst = data_dir / 'validation' / label.name / file_path.name\n",
    "            else:\n",
    "                dst = data_dir / 'test' / label.name / file_path.name\n",
    "\n",
    "            shutil.move(str(file_path), str(dst))  # Move file\n",
    "\n",
    "        # Check if the folder is empty before deletion\n",
    "        if any(label.iterdir()):  \n",
    "            print(f\"⚠️ Not empty, skipping: {label}\")\n",
    "        else:\n",
    "            label.rmdir()\n",
    "            print(f\"🗑️ Deleted empty folder: {label}\")\n",
    "\n",
    "    print(\"✅ Dataset split completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21185371",
   "metadata": {},
   "source": [
    "Call the function to split the data with the following ratios:\n",
    "\n",
    "- Train = 70%\n",
    "- Test = 20%\n",
    "- Validation = 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeba2193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Deleted empty folder: inputs\\cherry-leaves\\cherry-leaves\\healthy\n",
      "🗑️ Deleted empty folder: inputs\\cherry-leaves\\cherry-leaves\\powdery_mildew\n",
      "✅ Dataset split completed successfully!\n"
     ]
    }
   ],
   "source": [
    "split_train_validation_test_images(data_dir=r\"inputs/cherry-leaves/cherry-leaves\",\n",
    "                                   train_ratio=0.7,\n",
    "                                   val_ratio=0.1,\n",
    "                                   test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e4b6d3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we have:\n",
    "\n",
    "- Installed the required packages\n",
    "- Installed Kaggle and the authentication token\n",
    "- Downloaded the image data from kaggle.com\n",
    "- Removed the image data from the zip folder, deleted the folder and Kaggle authentication token\n",
    "- Checked the image data for any non-image files\n",
    "- Split the images into train, test and validation sets\n",
    "\n",
    "When you are ready, move on to the next notebook where we will look at Data Visualizations!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
