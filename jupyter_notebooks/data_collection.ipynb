{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39095f92",
   "metadata": {},
   "source": [
    "# **Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabdd41a",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Download data from Kaggle and prepare it for processing\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- kaggle.json - authentication token\n",
    "- dataset - images\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- Generated dataset: inputs/datasets/mildew_dataset\n",
    "- Split dataset - train, test, validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9b545d",
   "metadata": {},
   "source": [
    "## Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee078de5",
   "metadata": {},
   "source": [
    "By default, the working directory is \"jupyter_notebooks\", where the notebook is running. However, we need to change the working directory to its parent folder so that file references align with the broader project structure.\n",
    "\n",
    "To do this, we first check the current working directory â€” note that the output below only displays the last two folders in the file path, rather than the full system path. This is done intentionally to prevent exposing the full local file path stored on my machine.\n",
    "\n",
    "**Any time you revisit this notebook after logging out, or open a different notebook for the first time, you must repeat these steps to ensure the working directory is always correctly set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750a5553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31994a0",
   "metadata": {},
   "source": [
    "Now we change the working directory from \"jupyter_notebooks\" to the parent directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349a9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory to its parent folder\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Confirmation message\n",
    "print(\"You set a new current directory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c796bd",
   "metadata": {},
   "source": [
    "Confirm the new current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5891f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that the directory has changed\n",
    "current_dir = os.getcwd()\n",
    "current_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d6abe4",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e03cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6089e89",
   "metadata": {},
   "source": [
    "## Install Kaggle\n",
    "\n",
    "Now we need to think about gathering our data. We will be downloading our images from kaggle.com so we first install kaggle to help with the download.\n",
    "\n",
    "For this you need to have your Kaggle Token handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c01e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install kaggle package\n",
    "%pip install kaggle==1.5.12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1299105c",
   "metadata": {},
   "source": [
    "Drag and drop your kaggle.json file (Kaggle Token) into the same directory as README.md.\n",
    "\n",
    "The code below will check that kaggle.json appears in the directory by listing its contents. You should see a list of entries in this directory, including kaggle.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fd9627",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir())  # Should list `kaggle.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b74b17e",
   "metadata": {},
   "source": [
    "Now we get the path for the dataset and set the destination folder where the downloaded images will be stored.\n",
    "\n",
    "This code will download a zip folder, then create new folders (\"inputs\" and \"cherry-leaves\") for storing the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc536291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define Kaggle dataset and destination folder using pathlib\n",
    "KaggleDatasetPath = \"codeinstitute/cherry-leaves\"\n",
    "# Ensure correct path handling across OS\n",
    "DestinationFolder = Path(\"inputs\") / \"cherry-leaves\"\n",
    "\n",
    "# Download the Kaggle dataset into the specified folder\n",
    "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebdb5aa",
   "metadata": {},
   "source": [
    "Now we need to unzip the downloaded file and get hold of the images. \n",
    "\n",
    "The cell below will unzip the file and store the images inside a new directory within the \"inputs\" folder.\n",
    "\n",
    "The code will also delete the zip file and your Kaggle Token for data protection purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589138a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the file paths\n",
    "zip_file = Path(\"inputs\") / \"cherry-leaves\" / \"cherry-leaves.zip\"\n",
    "extract_folder = Path(\"inputs\") / \"cherry-leaves\"\n",
    "kaggle_token = Path(\"kaggle.json\")\n",
    "\n",
    "# Unzip the file and extract data\n",
    "with zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "\n",
    "print(f\"Extracted files into: {extract_folder}\")\n",
    "\n",
    "# Delete the zip file after extraction\n",
    "zip_file.unlink()\n",
    "print(f\"Deleted: {zip_file}\")\n",
    "\n",
    "# Remove Kaggle token for security purposes\n",
    "if kaggle_token.exists():\n",
    "    kaggle_token.unlink()\n",
    "    print(f\"Kaggle Token removed: {kaggle_token}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe6268",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Now we have the images downloaded and stored in the right place, we need to check that the data is suitable for our project.\n",
    "\n",
    "As we are concerned with using image data, we need to check that any non-image files are identified and removed.\n",
    "\n",
    "The function below will do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def remove_non_image_files(my_data_dir):\n",
    "    \"\"\"\n",
    "    Removes all non-image files from the specified directory \n",
    "    and its subfolders.\n",
    "\n",
    "    Args:\n",
    "        my_data_dir (str): Path to the directory containing image folders.\n",
    "\n",
    "    The function scans each folder within `my_data_dir`, identifies non-image \n",
    "    files, deletes them, and prints a summary of the number of image and \n",
    "    non-image files per folder.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define valid image file extensions\n",
    "    image_extensions = {'.png', '.jpg', '.jpeg'}\n",
    "\n",
    "    # Convert directory path to Path object for better handling\n",
    "    my_data_dir = Path(my_data_dir)\n",
    "\n",
    "    # Check if directory exists\n",
    "    if not my_data_dir.exists():\n",
    "        print(f\"Directory does not exist: {my_data_dir}\")\n",
    "        return\n",
    "\n",
    "    # Iterate through each folder in the main directory\n",
    "    for folder in my_data_dir.iterdir():\n",
    "        if folder.is_dir():  # Ensure only directories are processed\n",
    "            image_count, non_image_count = 0, 0  # Initialize counters\n",
    "\n",
    "            # Iterate through files inside the folder\n",
    "            for given_file in folder.iterdir():\n",
    "                # Convert suffix safely and check extension\n",
    "                if given_file.suffix and given_file.suffix.lower() \\\n",
    "                        not in image_extensions:\n",
    "                    given_file.unlink()  # Remove non-image file\n",
    "                    non_image_count += 1\n",
    "                else:\n",
    "                    image_count += 1\n",
    "\n",
    "            # Print summary of processed files\n",
    "            print(f\"Folder: {folder.name} - {image_count} image files\")\n",
    "            print(f\"Folder: {folder.name} - {non_image_count} non-image files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb21748",
   "metadata": {},
   "source": [
    "Now we call the function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62769aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_non_image_files(my_data_dir=r'inputs/cherry-leaves/cherry-leaves')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da492483",
   "metadata": {},
   "source": [
    "## Split the Data\n",
    "\n",
    "Now that we know the data is all images, we can split it into the groups we will need to build and fit a training model. These groups are:\n",
    "\n",
    "- Train set\n",
    "- Test set\n",
    "- Validation set\n",
    "\n",
    "The function below will create subfolders and split the data amongst them according to the arguments we define when calling the function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "\n",
    "def split_train_validation_test_images(\n",
    "    data_dir, train_ratio, val_ratio, test_ratio\n",
    "):\n",
    "    \"\"\"\n",
    "    Splits images into train, validation, and test sets based on given ratios.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str or Path): Directory containing subfolders of images,\n",
    "            where each subfolder represents a class label.\n",
    "        train_ratio (float): Proportion of images allocated to training.\n",
    "        val_ratio (float): Proportion of images allocated to validation.\n",
    "        test_ratio (float): Proportion of images allocated to testing.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If train_ratio, val_ratio, and test_ratio\n",
    "        do not sum to 1.0.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the ratios sum to 1.0 (rounded for floating-point precision)\n",
    "    if round(train_ratio + val_ratio + test_ratio, 5) != 1.0:\n",
    "        raise ValueError(\"ratios must sum to 1.0\")\n",
    "\n",
    "    # Convert data_dir to Path object if not already an object\n",
    "    data_dir = Path(data_dir)\n",
    "\n",
    "    # Get only directories (class labels) inside the dataset directory\n",
    "    labels = [label for label in data_dir.iterdir() if label.is_dir()]\n",
    "\n",
    "    # Create train, validation, and test directories\n",
    "    for folder in ['train', 'validation', 'test']:\n",
    "        for label in labels:\n",
    "            (data_dir / folder / label.name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for label in labels:\n",
    "        # List only files and ignore subdirectories\n",
    "        files = [f for f in label.iterdir() if f.is_file()]\n",
    "        random.shuffle(files)  # Shuffle for randomness\n",
    "\n",
    "        # Calculate split indices\n",
    "        train_count = int(len(files) * train_ratio)\n",
    "        val_count = int(len(files) * val_ratio)\n",
    "\n",
    "        # Move files to corresponding directories\n",
    "        for i, file_path in enumerate(files):\n",
    "            dst = (\n",
    "                data_dir / 'train' / label.name / file_path.name\n",
    "                if i < train_count else\n",
    "                data_dir / 'validation' / label.name / file_path.name\n",
    "                if i < train_count + val_count else\n",
    "                data_dir / 'test' / label.name / file_path.name\n",
    "            )\n",
    "\n",
    "            shutil.move(str(file_path), str(dst))  # Move file\n",
    "\n",
    "        # Check if folder is empty before deletion\n",
    "        if any(label.iterdir()):\n",
    "            print(f\"Not empty, skipping: {label}\")\n",
    "        else:\n",
    "            label.rmdir()\n",
    "            print(f\"Deleted empty folder: {label}\")\n",
    "\n",
    "    print(\"Dataset split completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21185371",
   "metadata": {},
   "source": [
    "Call the function to split the data with the following ratios:\n",
    "\n",
    "- Train = 70%\n",
    "- Test = 20%\n",
    "- Validation = 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba2193",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_validation_test_images(\n",
    "    data_dir=r\"inputs/cherry-leaves/cherry-leaves\",\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.1,\n",
    "    test_ratio=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fca801f",
   "metadata": {},
   "source": [
    "### Count number of images in each folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd1da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def count_images(folder_path):\n",
    "    \"\"\"\n",
    "    Counts the number of image files in the specified folder.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str or Path): Path to the folder containing images.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of image files in the folder.\n",
    "    \"\"\"\n",
    "    folder = Path(folder_path)\n",
    "    return sum(1 for f in folder.iterdir() if f.is_file())\n",
    "\n",
    "\n",
    "# Define base dataset directory\n",
    "base_dir = Path(\"inputs/cherry-leaves/cherry-leaves\")\n",
    "\n",
    "# Print image counts for each dataset split\n",
    "print(f\"Healthy Train: {\n",
    "    count_images(base_dir / 'train' / 'healthy')}\")\n",
    "print(f\"Powdery Mildew Train: {\n",
    "    count_images(base_dir / 'train' / 'powdery_mildew')}\")\n",
    "print(f\"Healthy Validation: {\n",
    "    count_images(base_dir / 'validation' / 'healthy')}\")\n",
    "print(f\"Powdery Mildew Validation: {\n",
    "    count_images(base_dir / 'validation' / 'powdery_mildew')}\")\n",
    "print(f\"Healthy Test: {\n",
    "    count_images(base_dir / 'test' / 'healthy')}\")\n",
    "print(f\"Powdery Mildew Test: {\n",
    "    count_images(base_dir / 'test' / 'powdery_mildew')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e4b6d3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we have:\n",
    "\n",
    "- Installed the required packages\n",
    "- Installed Kaggle and the authentication token\n",
    "- Downloaded the image data from kaggle.com\n",
    "- Removed the image data from the zip folder, deleted the folder and Kaggle authentication token\n",
    "- Checked the image data for any non-image files\n",
    "- Split the images into train, test and validation sets\n",
    "- Counted how many images are in each folder\n",
    "\n",
    "When you are ready, move on to the next notebook where we will look at Data Visualizations!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
