{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60de0524",
   "metadata": {},
   "source": [
    "# Modelling and Evaluation\n",
    "\n",
    "**Make sure that you have run data_collection.ipynb before running this one.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8518ee75",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- To address business requirement 2:\n",
    "  - The client wants to know if a given image of a cherry leaf is healthy or shows powdery mildew.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "This notebook will use the following inputs:\n",
    "\n",
    "- inputs/cherry-leaves/cherry-leaves/test\n",
    "- inputs/cherry-leaves/cherry-leaves/train\n",
    "- inputs/cherry-leaves/cherry-leaves/validation\n",
    "- outputs/v1/image_shape.pkl\n",
    "\n",
    "## Outputs\n",
    "\n",
    "This notebook will generate the following outputs:\n",
    "\n",
    "- Plot showing the number of images in the train, validation, and test sets.\n",
    "- Image augmentation.\n",
    "- Class indices to change prediction inference in labels.\n",
    "- Machine learning model creation and training.\n",
    "- Saved model.\n",
    "- Learning curve plot for model performance.\n",
    "- Model evaluation on pickle file.\n",
    "- Prediction on the random image file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f734ad22",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49940428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import joblib\n",
    "import pickle\n",
    "import tensorflow\n",
    "from matplotlib.image import imread\n",
    "from PIL import Image\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397af48f",
   "metadata": {},
   "source": [
    "## Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d50a9f",
   "metadata": {},
   "source": [
    "By default, the working directory is \"jupyter_notebooks\", where the notebook is running. However, we need to change the working directory to its parent folder so that file references align with the broader project structure.\n",
    "\n",
    "To do this, we first check the current working directory â€” note that the output below only displays the last two folders in the file path, rather than the full system path. This is done intentionally to prevent exposing the full local file path stored on my machine.\n",
    "\n",
    "**Any time you revisit this notebook after logging out, or open a different notebook for the first time, you must repeat these steps to ensure the working directory is always correctly set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebdfae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "current_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238fa4f9",
   "metadata": {},
   "source": [
    "Now we change the working directory from \"jupyter_notebooks\" to the parent directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b028a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory to its parent folder\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Confirmation message with\n",
    "print(\"You set a new current directory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db91d526",
   "metadata": {},
   "source": [
    "Confirm the new current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671ff9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "current_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e9e82b",
   "metadata": {},
   "source": [
    "## Set the input directories\n",
    "\n",
    "Now we need to define the paths where this notebook will find the data we'll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69e9aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base image data path\n",
    "image_data = Path(\"inputs\") / \"cherry-leaves\" / \"cherry-leaves\"\n",
    "\n",
    "# Define paths for train, validation, and test sets\n",
    "train_path = image_data / \"train\"\n",
    "val_path = image_data / \"validation\"\n",
    "test_path = image_data / \"test\"\n",
    "\n",
    "# Print paths\n",
    "print(f\"Train Path: {train_path}\")\n",
    "print(f\"Validation Path: {val_path}\")\n",
    "print(f\"Test Path: {test_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162bcfb5",
   "metadata": {},
   "source": [
    "### Confirm that the file paths are valid\n",
    "\n",
    "Now we'll run a function just to check that the file paths defined above are valid.\n",
    "\n",
    "The function will select one image from each train, test and validation folder and display it below along with the file path beginning with the \"inputs\" folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36853b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_random_image(parent_folder):\n",
    "    \"\"\"\n",
    "    Selects and displays a random image from a subfolder inside the given\n",
    "    parent directory.\n",
    "\n",
    "    Args:\n",
    "        parent_folder (str | Path): Path to dataset folder (e.g., train, val).\n",
    "\n",
    "    Returns:\n",
    "        str | None: Path to the randomly selected image or None if not found.\n",
    "    \"\"\"\n",
    "\n",
    "    parent_folder = Path(parent_folder)  # Ensure it's a Path object\n",
    "\n",
    "    # Ensure the parent folder exists\n",
    "    if not parent_folder.exists():\n",
    "        print(f\"path does not exist: {parent_folder}\")\n",
    "        return None\n",
    "\n",
    "    # Scan subdirectories ('healthy', 'powdery_mildew')\n",
    "    subfolders = [f for f in parent_folder.iterdir() if f.is_dir()]\n",
    "\n",
    "    if not subfolders:\n",
    "        print(f\"no subfolders found in: {parent_folder}\")\n",
    "        return None\n",
    "\n",
    "    # Pick a random subfolder (class name)\n",
    "    chosen_folder = random.choice(subfolders)\n",
    "\n",
    "    # Find image files inside that subfolder\n",
    "    img_exts = {'.png', '.jpg', '.jpeg', '.bmp', '.webp'}\n",
    "    image_files = [\n",
    "        f for f in chosen_folder.iterdir()\n",
    "        if f.suffix.lower() in img_exts\n",
    "    ]\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"no images found in: {chosen_folder}\")\n",
    "        return None\n",
    "\n",
    "    # Select a random image and display it\n",
    "    chosen_image = random.choice(image_files)\n",
    "    image = Image.open(chosen_image)\n",
    "\n",
    "    # Extract folder name ('healthy'/'powdery_mildew') and dataset section\n",
    "    class_name = chosen_folder.name\n",
    "    dataset_section = parent_folder.name\n",
    "\n",
    "    # Display the image with correct labeling\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"'{class_name}' image from '{dataset_section}' folder\")\n",
    "    plt.axis(\"off\")  # Hide axes for a cleaner look\n",
    "    plt.show()\n",
    "\n",
    "    return str(chosen_image)  # Return path for confirmation\n",
    "\n",
    "\n",
    "# Fetch and display random images from each dataset section\n",
    "train_image = show_random_image(train_path)\n",
    "print(f\"random train image: {train_image}\")\n",
    "\n",
    "val_image = show_random_image(val_path)\n",
    "print(f\"random validation image: {val_image}\")\n",
    "\n",
    "test_image = show_random_image(test_path)\n",
    "print(f\"random test image: {test_image}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc57088",
   "metadata": {},
   "source": [
    "### Set Output Directory\n",
    "\n",
    "Create 'output' directory if it doesn't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ede63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the root directory\n",
    "root_dir = Path.cwd()  # Get current working directory\n",
    "version = \"v1\"\n",
    "\n",
    "# Construct the relative path for outputs\n",
    "file_path = Path(\"outputs\") / version\n",
    "\n",
    "# Check if the directory for this version already exists\n",
    "if file_path.exists():\n",
    "    print(f'Old version \"{version}\" already exists.')\n",
    "    print(f'Create a new version if required. If not, you are good to go!')\n",
    "else:\n",
    "    try:\n",
    "        # Create the directory if it doesn't exist\n",
    "        file_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f'Created new directory: {file_path}')\n",
    "    except OSError as e:\n",
    "        print(f'Error creating directory: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37b7c8",
   "metadata": {},
   "source": [
    "## Set the Label Names\n",
    "\n",
    "Our upcoming binary classification task will require labelled data in order to train. Here we will set the labels to be used in our project:\n",
    "\n",
    "- 'healthy'\n",
    "- 'powdery_mildew'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df51f265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the labels\n",
    "labels = os.listdir(train_path)\n",
    "print('The labels for the images are', labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e32608",
   "metadata": {},
   "source": [
    "## Let's Count the Images\n",
    "\n",
    "In the Data Collection notebook, we downloaded two directories of images:\n",
    "\n",
    "- healthy\n",
    "- powdery_mildew\n",
    "  \n",
    "We then split the images in each directory into three further folders:\n",
    "\n",
    "- test\n",
    "- train\n",
    "- validation\n",
    "\n",
    "In this notebook, we now need to count how many images are in each of these six folders. We will create a loop to do the count then display the results in a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d725b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an empty dictionary\n",
    "data = {'Set': [], 'Label': [], 'Frequency': []}\n",
    "\n",
    "# Define dataset partitions\n",
    "folders = ['train', 'validation', 'test']\n",
    "\n",
    "# Define root dataset directory\n",
    "image_data = Path(\"inputs/cherry-leaves/cherry-leaves\")\n",
    "# Extract class labels dynamically from 'train' subdirectories\n",
    "train_path = image_data / \"train\"\n",
    "\n",
    "# Extract directory names\n",
    "labels = [\n",
    "    label.name for label in train_path.iterdir()\n",
    "    if label.is_dir()\n",
    "]\n",
    "\n",
    "# Collect data efficiently\n",
    "for folder in folders:\n",
    "    for label in labels:\n",
    "        label_path = image_data / folder / label  # Use Path object\n",
    "\n",
    "        # Count files if path exists\n",
    "        num_images = (\n",
    "            len(list(label_path.glob(\"*\"))) if label_path.exists()\n",
    "            else 0\n",
    "        )\n",
    "\n",
    "        data['Set'].append(folder)\n",
    "        data['Label'].append(label)\n",
    "        data['Frequency'].append(num_images)\n",
    "\n",
    "        print(f\"{folder} - {label}: {num_images} images\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_freq = pd.DataFrame(data)\n",
    "\n",
    "# Create the figure object\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Define custom colors\n",
    "custom_colors = [\n",
    "    \"#582088\", \"#33FFC29F\"\n",
    "]\n",
    "\n",
    "# Plot with updated colors\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.barplot(\n",
    "    data=df_freq, x='Set', y='Frequency', hue='Label',\n",
    "    palette=custom_colors, ax=ax\n",
    ")\n",
    "\n",
    "# Show plot (figure remains stored in 'fig' for later saving)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d716d",
   "metadata": {},
   "source": [
    "### Save the plot\n",
    "\n",
    "If you're happy with the plot layout and colour scheme, save it in the 'outputs/v1' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba92d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(file_path) / \"labels_distribution.png\"\n",
    "fig.savefig(save_path, bbox_inches=\"tight\", dpi=150)\n",
    "\n",
    "print(\"Plot saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07aeed4",
   "metadata": {},
   "source": [
    "As we can see from the count, we have equal numbers of 'healthy' and 'powdery_mildew' images across the train, test and validation folders. Had the numbers been unequal, we would have given consideration to data balancing (oversampling or undersampling). As it stands, we don't need to do any data balancing so we can now move on to data augmentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b240ea5a",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Currently all our images look roughly the same in terms of size, aspect and zoom, for example. To build a more robust machine learning model we need to 'rough up' our dataset a little. Real world images won't always look like the uniform set of images that we downloaded so we need the model to learn using an 'augmented' dataset. An augmented dataset introduces variations such as random rotations, cropping, zoom adjustments, brightness shifts, and flipping to simulate the unpredictability of real-world images.\n",
    "\n",
    "This process helps the model to generalize better by learning from a diverse set of image transformations. By applying augmentation techniques, we can effectively enhance the robustness of our machine learning model, making it more resilient to variations in new and unseen data.\n",
    "\n",
    "So, let's get to it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ce9d2",
   "metadata": {},
   "source": [
    "### Import ImageDataGenerator\n",
    "\n",
    "First we'll import the right packages from tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2274b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define image generator with normalization values for pixels\n",
    "image_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(\"Image generator initialized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca5720",
   "metadata": {},
   "source": [
    "Let's now define the adjustments that we want to make. Credit Code Institute WalkthroughProject01 for initial parameter selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image data generator with various augmentations\n",
    "augmented_image_data = ImageDataGenerator(\n",
    "\n",
    "    # Rotation to introduce perspective shifts\n",
    "    rotation_range=25,\n",
    "\n",
    "    # Shift image horizontally by 15% of image width\n",
    "    width_shift_range=0.15,\n",
    "\n",
    "    # Shift image vertically by 15% of image height\n",
    "    height_shift_range=0.15,\n",
    "\n",
    "    # Slants the image along both axes by up to 20%\n",
    "    shear_range=0.2,\n",
    "\n",
    "    # Zoom in or out by up to 20%\n",
    "    zoom_range=0.2,\n",
    "\n",
    "    # Flip images horizontally\n",
    "    horizontal_flip=True,\n",
    "\n",
    "    # Flip images vertically\n",
    "    vertical_flip=True,\n",
    "\n",
    "    # Brightness adjusts between 70% - 130%\n",
    "    brightness_range=(0.7, 1.3),\n",
    "\n",
    "    # Shift RGB channels by 20 units for variance\n",
    "    channel_shift_range=20,\n",
    "\n",
    "    # Fill missing pixels with nearest neighbor interpolation\n",
    "    fill_mode='nearest',\n",
    "\n",
    "    # Normalize pixel values to scale between 0 and 1\n",
    "    rescale=1./255\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6773faea",
   "metadata": {},
   "source": [
    "### Augmentation notes\n",
    "\n",
    "We are going to be augmenting the image data in real-time by using ImageDataGenerator's flow_from_directory() method. This means that the images will be modified dynamically as they enter the model. This ensures that the model sees new variations of images in every epoch, helping it learn generalized patterns rather than memorizing specific features.\n",
    "\n",
    "In the data visualization notebook, we calculated the average image shape and stored that value in 'image_shape.pkl'. The model that we will be developing will need to know the dimensions of the images we will be training. To reduce the size of the .keras file that we will be generating, we will be defining a custom image shape in the cell block.\n",
    "\n",
    "We may experiment with batch size as we fine-tune the model. Adjusting batch size impacts training speed and memory efficiency, so we may modify this value, if needed, to optimize performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5e9e3",
   "metadata": {},
   "source": [
    "### Define the image shape manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6024d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image shape manually\n",
    "image_shape = (128, 128, 3)  # Example: (height, width, channels)\n",
    "\n",
    "print(f\"Using manually defined image shape: {image_shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc104a2",
   "metadata": {},
   "source": [
    "### Augment the train image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08f10cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define batch size for training\n",
    "# 8 balances memory efficiency & training speed after trial and error\n",
    "batch_size = 8\n",
    "\n",
    "# Convert train_path to a Path object\n",
    "train_path = Path(\"inputs/cherry-leaves/cherry-leaves/train\")\n",
    "if not train_path.exists():\n",
    "    raise FileNotFoundError(f\"Training directory {train_path} not found!\")\n",
    "\n",
    "# Extract width & height from stored image shape\n",
    "target_size = tuple(image_shape[:2])\n",
    "\n",
    "# Load training dataset with augmentation\n",
    "train_set = augmented_image_data.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Check dataset summary\n",
    "print(f\"Using batch size: {batch_size}\")\n",
    "print(f\"Found {train_set.samples} images belonging to {\n",
    "    len(train_set.class_indices)} classes.\")\n",
    "print(f\"Class mapping: {train_set.class_indices}\")\n",
    "\n",
    "# Load a sample batch to verify the image size\n",
    "sample_images, _ = next(train_set)  # Fetch first batch\n",
    "\n",
    "# Expected: (batch_size, {target_size[0]}, {target_size[1]}, 3)\n",
    "print(f\"Sample image batch shape: {sample_images.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e12633",
   "metadata": {},
   "source": [
    "### Augment test image data\n",
    "\n",
    "Now, when it comes to augmenting test image data, we are only going to worry about resizing the images. This is because the test images should be as close as possible to the 'real world' images that will be uploaded by the users.\n",
    "\n",
    "As you can see from the variable below, we are only going to make use of the rescale parameter in the ImageDataGenerator class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c942e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract width & height\n",
    "target_size = tuple(image_shape[:2])\n",
    "\n",
    "# Define the correct test path\n",
    "test_path = Path(\"inputs/cherry-leaves/cherry-leaves/test\")\n",
    "\n",
    "# Validate path existence to prevent errors\n",
    "if not test_path.exists():\n",
    "    raise FileNotFoundError(f\"Test directory {test_path} not found!\")\n",
    "\n",
    "# Load test dataset with augmentation\n",
    "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    str(test_path),  # Ensure compatibility by converting Path to string\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",  # Loads images in RGB format\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False  # Keeps data order unchanged for consistent evaluation\n",
    ")\n",
    "\n",
    "# Check dataset summary\n",
    "print(f\"Using batch size: {batch_size}\")  # Confirm batch size\n",
    "print(f\"Found {test_set.samples} images belonging to {\n",
    "    len(test_set.class_indices)} classes.\")\n",
    "print(f\"Class mapping: {test_set.class_indices}\")\n",
    "\n",
    "# Load a sample batch to verify image size\n",
    "sample_images, _ = next(test_set)  # Fetch first batch\n",
    "\n",
    "# Expected: (batch_size, {target_size[0]}, {target_size[1]}, 3)\n",
    "print(f\"Sample image batch shape: {sample_images.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a395e9",
   "metadata": {},
   "source": [
    "### Augment validation image data\n",
    "\n",
    "The same logic applies to the validation image data. This should also match 'real world' data as closely as possible.\n",
    "\n",
    "Notice that the basic code for augmenting the validation data is the same as that for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90729cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Extract width & height\n",
    "target_size = tuple(image_shape[:2])\n",
    "\n",
    "# Define the correct validation path\n",
    "val_path = Path(\"inputs/cherry-leaves/cherry-leaves/validation\")\n",
    "\n",
    "# Validate path existence to prevent errors\n",
    "if not val_path.exists():\n",
    "    raise FileNotFoundError(f\"Validation directory {val_path} not found!\")\n",
    "\n",
    "# Load validation dataset\n",
    "val_set = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    str(val_path),  # Convert Path to string\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",  # Loads images in RGB format\n",
    "    batch_size=batch_size,  # Define batch size\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False  # Ensures consistent evaluation during validation\n",
    ")\n",
    "\n",
    "# Print dataset summary\n",
    "print(f\"Using batch size: {batch_size}\")\n",
    "print(f\"Found {val_set.samples} images belonging to {\n",
    "    len(val_set.class_indices)} classes.\")\n",
    "print(f\"Class mapping: {val_set.class_indices}\")\n",
    "\n",
    "# Load a sample batch to verify image size\n",
    "sample_images, _ = next(val_set)  # Fetch first batch\n",
    "\n",
    "# Expected: (batch_size, {target_size[0]}, {target_size[1]}, 3)\n",
    "print(f\"Sample image batch shape: {sample_images.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66feb317",
   "metadata": {},
   "source": [
    "### Save class indices for later use\n",
    "\n",
    "Let's now save the class indices into a .pkl file for later use. This will be required when deploying our model to ensure class labels remain consistent during inference (making predictions on unseen data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f610138",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure file_path is a Path object\n",
    "file_path = Path(file_path)\n",
    "\n",
    "# Save class indices to a file using Pathlib\n",
    "output_file = file_path / \"class_indices.pkl\"\n",
    "joblib.dump(value=train_set.class_indices, filename=output_file)\n",
    "\n",
    "print(f\"File saved: '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2679b240",
   "metadata": {},
   "source": [
    "### Let's take a look at some examples the augmented images\n",
    "\n",
    "Before we start modelling, letâ€™s take a look at some samples of the augmented image data. The function below can be used to pull some random images from the directories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b99b3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_augmented_samples(train_set, val_set, test_set):\n",
    "    \"\"\"Displays three randomly selected augmented images from each dataset \n",
    "    (train, validation, test) in a 3x3 plot.\n",
    "\n",
    "    Args:\n",
    "        train_set (tf.data.Dataset): Augmented training dataset.\n",
    "        val_set (tf.data.Dataset): Augmented validation dataset.\n",
    "        test_set (tf.data.Dataset): Augmented test dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "    dataset_names = [\"Train\", \"Validation\", \"Test\"]\n",
    "    datasets = [train_set, val_set, test_set]\n",
    "\n",
    "    # Iterate through datasets with names for plotting\n",
    "    for col, (dataset_name, dataset) in enumerate(\n",
    "        zip(dataset_names, datasets)\n",
    "    ):\n",
    "        # Generate random indices for batch selection\n",
    "        random_indices = np.random.randint(0, dataset.batch_size, 3)\n",
    "\n",
    "        for row, idx in enumerate(random_indices):\n",
    "            # Select images at random positions in batch\n",
    "            img, label = next(dataset)  # Fetch a batch\n",
    "            img = img[idx]  # Extract random image from batch\n",
    "\n",
    "            # Display the images in the subplot\n",
    "            axes[row, col].imshow(img)  \n",
    "            # Hide axis for cleaner view\n",
    "            axes[row, col].axis(\"off\")  \n",
    "\n",
    "            if row == 0:\n",
    "                axes[row, col].set_title(\n",
    "                    dataset_name, fontsize=14, fontweight=\"bold\"\n",
    "                )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c9051e",
   "metadata": {},
   "source": [
    "Now call the function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc0e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_augmented_samples(train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a387d6f9",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "Now we need to create a model that trains on our augmented dataset. This training will seek to identify patterns in the images and accurately classify cherry leaves as either healthy or affected by powdery mildew. \n",
    "\n",
    "This next step involves designing a deep learning model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ca926c",
   "metadata": {},
   "source": [
    "### Import the right tensor packages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e97a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow components for model training\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, \\\n",
    "    img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Activation, Dropout, Flatten, Dense,\n",
    "                                     Conv2D, MaxPooling2D, Input,\n",
    "                                     BatchNormalization)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"TensorFlow methods imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1aa307",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "The following [model](https://github.com/Duffew/mildew_detector#the-model) is a sequential convolutional neural network designed to perform a binary classification task; learning to differentiate between healthy and mildewed cherry leaves.  \n",
    "\n",
    "Credit Code Institute WalkthoughProject01 for the initial model structure.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420eddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_model(input_shape=image_shape):\n",
    "    \"\"\"\n",
    "    Create a sequential Convolutional Neural Network for binary\n",
    "    classification of leaf images.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Image shape (height, width, channels).\n",
    "\n",
    "    Returns:\n",
    "        Sequential: Compiled TensorFlow model ready for training.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(\n",
    "        32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # L2 added to help prevent overfitting by penalizing large weight values\n",
    "    # Added in response to validation accuracy issues in\n",
    "    # previous model iterations\n",
    "    model.add(layers.Dense(128, activation='relu',\n",
    "                           kernel_regularizer=l2(0.0005)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc97789",
   "metadata": {},
   "source": [
    "#### Create a model summary\n",
    "\n",
    "We do this so that we can visually inspect the model architecture, verify layer configurations, check input/output shapes, and ensure the number of trainable parameters aligns with our expectations before training begins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda88556",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tf_model().summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a148e3b6",
   "metadata": {},
   "source": [
    "#### Early stopping\n",
    "\n",
    "As the model learns it should get more accurate over the epochs. At some point, the learning will slow and improvements will become minimal. Once this begins to happen, we can stop the training early to help prevent overfitting, ensuring the model does not memorize the training data but generalizes well on unseen data.\n",
    "\n",
    "The variable below can be used to stop the training when after 3 epochs (patience=3), value loss stops improving (monitor='val_loss'). This variable will also restore the weights from the best performing epoch (restore_best_weights=True) which will then become the inference model used by the client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77573a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', patience=3, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a5fb5",
   "metadata": {},
   "source": [
    "Before fitting the model, letâ€™s just check how the training data is broken down.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a55e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total training images: {train_set.samples}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Calculated steps_per_epoch: {train_set.samples // batch_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9dfb99",
   "metadata": {},
   "source": [
    "### Fit the model\n",
    "\n",
    "Run the cell below to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a785781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model for training\n",
    "\n",
    "# Create the model\n",
    "model = create_tf_model()\n",
    "\n",
    "# Train the model\n",
    "steps_per_epoch = train_set.samples // batch_size\n",
    "\n",
    "model.fit(\n",
    "    train_set,\n",
    "    epochs=25,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_set,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b36488",
   "metadata": {},
   "source": [
    "#### Save model\n",
    "\n",
    "Now we save the model with the best weights to a .keras file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbeb618",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"outputs/v1/mildew_detector_model.keras\"\n",
    "model.save(save_path)\n",
    "\n",
    "# Get file size in MB\n",
    "file_size_mb = os.path.getsize(save_path) / (1024 * 1024)\n",
    "\n",
    "print(f\"File saved: '{save_path}' | Size: {file_size_mb:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeea851",
   "metadata": {},
   "source": [
    "#### Model performance\n",
    "\n",
    "Now that the model has been fitted, we need to assess its performance. The code below will generate a couple of plots to show the training loss compared to the validation loss, and the training accuracy compared to the validation accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom colours to apply to the plots\n",
    "custom_colors = [\"#582088\", \"#33FFC29F\"]\n",
    "\n",
    "# Define source of performance data\n",
    "perform_data = pd.DataFrame(model.history.history)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Loss plot using custom colours and saved in v1\n",
    "perform_data[['loss', 'val_loss']].plot(style='.-', color=custom_colors)\n",
    "plt.title(\"Loss\")\n",
    "plt.savefig(f'{\n",
    "    file_path}/model_training_losses.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Accuracy plot using custom colours and saved in v1\n",
    "perform_data[['accuracy', 'val_accuracy']].plot(\n",
    "    style='.-', color=custom_colors)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.savefig(f'{\n",
    "    file_path}/model_training_acc.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2015990a",
   "metadata": {},
   "source": [
    "The following code will display the saved plots so we can see the performance - use this code block if you don't want to re-run the model but have access to the saved plots in outputs/v1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328c57f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the output folder\n",
    "output_dir = Path(\"outputs/v1\")  # Adjust if needed\n",
    "\n",
    "# List of saved plots\n",
    "plot_files = [\"model_training_acc.png\", \"model_training_losses.png\"]\n",
    "\n",
    "# Display each plot\n",
    "for plot_file in plot_files:\n",
    "    plot_path = output_dir / plot_file  # Construct the full path\n",
    "    if plot_path.exists():\n",
    "        img = plt.imread(plot_path)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(plot_file)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"File not found: {plot_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11100c26",
   "metadata": {},
   "source": [
    "#### Performance summary\n",
    "\n",
    "The above plots show that validation accuracy started high and remained high across all epochs. It stayed consistently above training accuracy, which started low but jumped quickly above 94% and peaked at 98.86% in epoch 6. This suggests rapid learning early in the training. While validation accuracy remained stable, there were slight fluctuations in later epochs that might warrant further investigation.\n",
    "\n",
    "Similarly, the loss values for the training data show rapid declines as the epochs progressed. Validation loss peaked in the second epoch at 0.1441, then dropped and mostly stayed below 0.1, with slight fluctuations. This suggests confident generalization. As validation losses plateaued, it is likely that training stopped early due to patience becoming exhausted - early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True).\n",
    "\n",
    "These results suggest that this model is high performing, learns quickly and maintains excellent validation accuracy. Although there are some slight variations in validation loss, the model seems to generalise well \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67ad78b",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "\n",
    "Run the following code cell to evaluate the fitted model using the test set image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebc5b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b39fc",
   "metadata": {},
   "source": [
    "Now save the evaluation in a .pkl file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08587d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=evaluation,\n",
    "            filename=f\"outputs/v1/evaluation.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d8fd1",
   "metadata": {},
   "source": [
    "#### Predict on new data\n",
    "\n",
    "The code block below will select and load an image from the test set to be used by the model to infer classification.\n",
    "\n",
    "If you want to change the image, adjust the 'pointer' value. If you want test on a different category, adjust the 'label' value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aecadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Define pointer & label - adjust pointer number to see different test images\n",
    "pointer = 42\n",
    "label = labels[1]  # Select \"healthy\" - [0] or \"mildewed\" - [1]\n",
    "\n",
    "# Get image directory and file list\n",
    "image_dir = Path(test_path) / label\n",
    "image_files = list(image_dir.iterdir())\n",
    "\n",
    "# Ensure pointer is within range\n",
    "if pointer >= len(image_files):\n",
    "    raise IndexError(f\"Pointer index {\n",
    "        pointer} exceeds available images({len(image_files)}).\")\n",
    "\n",
    "# Load image\n",
    "image_path = image_files[pointer]\n",
    "pil_image = image.load_img(\n",
    "    image_path, target_size=image_shape, color_mode='rgb')\n",
    "\n",
    "# Display image details\n",
    "print(f\"Image Path: {image_path}\")\n",
    "print(f\"Image Shape: {pil_image.size}, Image Mode: {pil_image.mode}\")\n",
    "\n",
    "# Show image\n",
    "plt.imshow(pil_image)\n",
    "plt.axis(\"off\")\n",
    "plt.title(image_path.name)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d09754",
   "metadata": {},
   "source": [
    "Now prepare the image for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d5a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the PIL image to a NumPy array\n",
    "my_image = image.img_to_array(pil_image)  # Converts RGB image into an array\n",
    "\n",
    "# Expand dimensions to match the expected input shape for the model\n",
    "my_image = np.expand_dims(my_image, axis=0)  # Adds a batch dimension\n",
    "\n",
    "# Normalize pixel values to range [0,1] for better model performance\n",
    "my_image = my_image / 255.0  # Standard normalization for neural network input\n",
    "\n",
    "# Print the shape to verify transformation\n",
    "print(f\"Processed Image Shape: {my_image.shape}\")\n",
    "print(f\"Training Image Shape: {image_shape}\")\n",
    "print(\"Processed image shape should match training image shape.\")\n",
    "print(\"Don't worry about the first number. It's the batch size for testing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54deca16",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "Run the following cell to predict the classification of the test image and see the model's confidence in that prediction. This code takes the numeric probability and turns it into a binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b31d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict raw probability\n",
    "raw_output = model.predict(my_image)[0, 0]\n",
    "\n",
    "# Map numerical predcitions to 'healthy' or 'powdery_mildew'\n",
    "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
    "\n",
    "# Determine predicted class - apply explicit type conversion at a 50% threshold\n",
    "pred_class = target_map[int(raw_output > 0.5)]\n",
    "\n",
    "# Adjust probability for binary classification\n",
    "pred_proba = np.abs(raw_output - (pred_class == target_map[0]))\n",
    "\n",
    "# Print results\n",
    "print(f\"Predicted Class: {pred_class}\")  # Classification\n",
    "print(f\"Raw Model Output: {raw_output:.9f}\")  # Raw output to 9 deciaml places\n",
    "print(f\"Confidence: {pred_proba:.4f}\")  # Confidence to 4 deciaml places\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6cccb3",
   "metadata": {},
   "source": [
    "#### Evaluation summary\n",
    "\n",
    "The model was evaluated using a set of unseen test data, split into 106 batches.\n",
    "\n",
    "The evaluation returned an accuracy of 0.9965 and a loss of 0.0909. Both metrics are in line with the validation figures observed during model fitting.\n",
    "\n",
    "Additionally, the model correctly identified an image of powdery mildew with a confidence level of 0.9998.\n",
    "\n",
    "Taken together, these results provide strong evidence that the model is highly accurate and reliable in detecting powdery mildew in cherry leaves. The model exceeds the client's requirement of 97% accuracy and is well-suited for deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf1aacd",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "That was a lot of work! Well done on getting this far! In this notebook we:\n",
    "\n",
    "- Counted the images in each folder and created a plot to show the numbers\n",
    "- Augmented the train, validation and test sets for training\n",
    "- Created a ML model to train on the data\n",
    "- Saved an ML model with the best weights\n",
    "- Assessed model performance in terms of 'accuracy' and 'loss'\n",
    "- Evaluated the saved model for 'accuracy' on an unseen test set\n",
    "- Predicted leaf health on unseen images\n",
    "\n",
    "Definitely time for a cup of tea before we put all this into a dashboard for our client!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
